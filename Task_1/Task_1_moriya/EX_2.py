import pandas as pd
from collections import Counter
import os

# === ×§×œ×˜ ××”××©×ª××© ===
file_name = input("×”×›× ×¡×™ ××ª ×©× ×”×§×•×‘×¥ (×œ×“×•×’××”: time_series.xlsx ××• time_series.parquet): ")
#"C:\Users\User\Desktop\Hadassim Home Test\Task_1\time_series.parquet"
full_path = fr"C:\Users\User\Desktop\Hadassim Home Test\Task_1\{file_name}"

# === ×§×¨×™××” ×“×™× ××™×ª ×©×œ ×”×§×•×‘×¥ ×‘×”×ª×× ×œ×¡×™×•××ª ===
if file_name.endswith('.xlsx'):
    file = pd.read_excel(full_path)
    value_col = 'value'
elif file_name.endswith('.parquet'):
    file = pd.read_parquet(full_path)
    value_col = 'mean_value'
else:
    raise ValueError("×¡×•×’ ×§×•×‘×¥ ×œ× × ×ª××š â€“ ×”×©×ª××©×™ ×‘×§×•×‘×¥ .xlsx ××• .parquet")

print("×”×¢××•×“×•×ª ×©×§×™×™××•×ª ×‘×§×•×‘×¥ ×”×Ÿ:", file.columns)

# === ×¡×¢×™×£ × â€“ ×‘×“×™×§×•×ª ××§×“×™××•×ª ===
try:
    file['timestamp'] = pd.to_datetime(file['timestamp'])
except Exception as e:
    print("âŒ ×©×’×™××” ×‘×¤×•×¨××˜ ×”×ª××¨×™×š:", e)

# ×‘×“×™×§×ª ×›×¤×™×œ×•×™×•×ª
duplicates = file.duplicated().sum()
print(f"ğŸ” ×™×© {duplicates} ×©×•×¨×•×ª ×›×¤×•×œ×•×ª ×‘×§×•×‘×¥")

# ×‘×“×™×§×ª ×¢×¨×›×™× ×—×¡×¨×™×
missing_val = file[value_col].isnull().sum()
print(f"ğŸ“­ ×¢×¨×›×™× ×—×¡×¨×™× ×‘×¢××•×“×ª value: {missing_val}")

# ×”××¨×ª ×¢×¨×›×™× ××¡×¤×¨×™×™× ×•× ×™×§×•×™ ×©×•×¨×•×ª ×œ× ×ª×§×™× ×•×ª
file[value_col] = pd.to_numeric(file[value_col], errors='coerce')
file = file.dropna(subset=['timestamp', value_col])

# === ×¡×¢×™×£ ×‘.1 â€“ ×××•×¦×¢ ×œ×¤×™ ×©×¢×” ===
file['Hour'] = file['timestamp'].dt.strftime('%Y-%m-%d %H:00')
avg_by_hour = file.groupby('Hour')[value_col].mean()
print("\nğŸ“Š ×××•×¦×¢ ×¢×¨×›×™× ×œ×¤×™ ×©×¢×”:")
print(avg_by_hour)

# === ×¡×¢×™×£ ×‘.2 â€“ ×¤×™×¦×•×œ ×œ×¤×™ ×™××™× ×•×©××™×¨×” ×œ×§×‘×¦×™× ===
file['date'] = file['timestamp'].dt.date
unique_dates = file['date'].unique()

folder_path = r"C:\Users\User\Desktop\Hadassim Home Test\Task_1\split_files"
os.makedirs(folder_path, exist_ok=True)

for day in unique_dates:
    daily_data = file[file['date'] == day]
    daily_file_name = fr"{folder_path}\day_{day}.xlsx"
    daily_data.to_excel(daily_file_name, index=False)

# === ×¡×¢×™×£ ×‘.3 â€“ ×××•×¦×¢ ×œ×¤×™ ×©×¢×” ×œ×›×œ ×™×•× ×•××™×—×•×“ ×”×ª×•×¦××•×ª ===
all_averages = []

for fname in os.listdir(folder_path):
    if fname.endswith('.xlsx'):
        daily_file = pd.read_excel(os.path.join(folder_path, fname))
        daily_file['timestamp'] = pd.to_datetime(daily_file['timestamp'])
        daily_file[value_col] = pd.to_numeric(daily_file[value_col], errors='coerce')
        daily_file = daily_file.dropna(subset=['timestamp', value_col])

        daily_file['Hour'] = daily_file['timestamp'].dt.strftime('%Y-%m-%d %H:00')
        avg_by_hour = daily_file.groupby('Hour')[value_col].mean().reset_index()

        all_averages.append(avg_by_hour)

final_result = pd.concat(all_averages)
final_result = final_result.sort_values('Hour')

# ×©××™×¨×” ×œ×§×•×‘×¥ ×¡×•×¤×™
output_path = r"C:\Users\User\Desktop\Hadassim Home Test\Task_1\final_result.csv"
final_result.to_csv(output_path, index=False)

print("âœ… ×”×§×•×‘×¥ ×”×¡×•×¤×™ × ×•×¦×¨ ×‘×”×¦×œ×—×” ×‘×©× final_result.csv")


# ×¡×¢×™×£ ×‘ ×ª×¨×’×™×œ 3
"""
×× ×”× ×ª×•× ×™× ×œ× ××’×™×¢×™× ×‘×§×•×‘×¥ ××—×“ ××œ× ×–×•×¨××™× ×›×œ ×”×–××Ÿ
×©××™ ××¤×©×¨ ×œ×—×›×•×ª ×©×›×œ ×”××™×“×¢ ×™×’×™×¢ ×•×¨×§ ××– ×œ×—×©×‘ ××ª ×”×××•×¦×¢.
×‘××§×•× ×–×”, ×¦×¨×™×š ×œ×—×©×‘ ××ª ×”×××•×¦×¢×™× ×ª×•×š ×›×“×™ ×©×”××™×“×¢ × ×›× ×¡.

×œ×¤×™ ×”×”×™×’×™×•×Ÿ ×©×œ×™, ×”×™×™×ª×™ ×©×•××¨×ª ×‘×›×œ ×¨×’×¢
 ××ª ×›××•×ª ×”×¢×¨×›×™× ×©×”×’×™×¢×• ×‘×›×œ ×©×¢×” ×•××ª ×”×¡×›×•× ×”×›×•×œ×œ ×©×œ×”×.
×•×›×©×™×’×™×¢ ×¢×•×“ ×¢×¨×š ×—×“×© â€“ 
× ×‘×“×•×§ ×œ××™×–×• ×©×¢×” ×”×•× ×©×™×™×š,
 × ×•×¡×™×£ ××ª ×”×¢×¨×š ×”×–×” ×œ×¡×›×•× ×©×œ ××•×ª×” ×©×¢×”,
×•× ×¢×œ×” ××ª ×”×¡×¤×™×¨×” ×‘××—×“.
×›×›×”, × ×•×›×œ ×œ×—×©×‘ ×××•×¦×¢ ×¤×©×•×˜ ×©×œ ×¡×›×•× ×—×œ×§×™ ×›××•×ª,
 ×‘×œ×™ ×œ×©××•×¨ ××ª ×›×œ ×”× ×ª×•× ×™× ×¢×¦×× â€“ 
 ×¨×§ ××ª ××” ×©×¦×¨×™×š ×‘×©×‘×™×œ ×”×××•×¦×¢.

×›×›×” ×’× × ×•×›×œ ×œ×”×¦×™×’ ×××•×¦×¢×™× ×©××ª×¢×“×›× ×™× ×‘×–××Ÿ ×××ª ×‘×œ×™ ×œ×”×¢××™×¡ ×¢×œ ×”×–×™×›×¨×•×Ÿ.
"""

# ×¡×¢×™×£ ×‘ ×ª×¨×’×™×œ 4
"""
 ×ª×™×¢×•×“ â€“ ×ª××™×›×” ×‘×¤×•×¨××˜ Parquet

1. ×ª××™×›×” ×‘×¡×•×’×™×  ×©×•× ×™×:

×‘×”×ª×× ×œ×“×¨×™×©×•×ª ×”×ª×¨×’×™×œ, ×¢×•×“×›×Ÿ ×”×§×•×“ ×›×š ×©×”×•× ××–×”×” ××ª ×¡×•×’ ×”×§×•×‘×¥ ×œ×¤×™ ×”×¡×™×•××ª:
- ×× ×”×¡×™×•××ª ×”×™× `.xlsx` â†’ ×”×§×•×‘×¥ × ×§×¨× ×‘×××¦×¢×•×ª `pd.read_excel`
 ×•×”×¢××•×“×” ×”×¨×œ×•×•× ×˜×™×ª ×”×™× `'value'`
- ×× ×”×¡×™×•××ª ×”×™× `.parquet` â†’ ×”×§×•×‘×¥ × ×§×¨× ×‘×××¦×¢×•×ª `pd.read_parquet`
×•×”×¢××•×“×” ×”×¨×œ×•×•× ×˜×™×ª ×”×™× `'mean_value'`

×”×§×•×“ ××ª××™× ××ª ×¢×¦××• ××•×˜×•××˜×™×ª ×›×š ×©××™×Ÿ ×¦×•×¨×š ×œ×©× ×•×ª ×™×“× ×™×ª ××ª ×©× ×”×¢××•×“×” ××• ××ª ×©×™×˜×ª ×”×§×¨×™××”.

2. ×™×ª×¨×•× ×•×ª ×¤×•×¨××˜ Parquet:
Parquet ×”×•× ×¤×•×¨××˜ ×¢××•×“×•×ª (columnar format) 
×“×—×•×¡ ×•×™×¢×™×œ, ×©× ×•×¢×“ ×œ××—×¡×•×Ÿ ×•× ×™×ª×•×— ×©×œ ×›××•×™×•×ª ××™×“×¢ ×’×“×•×œ×•×ª.

- **×“×—×™×¡×ª ××™×“×¢** â€“ ×§×‘×¦×™× ×§×˜× ×™× ×™×•×ª×¨ ×‘×”×©×•×•××” ×œÖ¾Excel ××• CSV
- **××”×™×¨×•×ª ×§×¨×™××” ×•×›×ª×™×‘×”** â€“ ×§×¨×™××” ×™×©×™×¨×” ×¨×§ ×©×œ ×”×¢××•×“×•×ª ×”×“×¨×•×©×•×ª
- **×™×¢×™×œ×•×ª ×‘×–×™×›×¨×•×Ÿ** â€“ ×—×•×¡×š ×‘×–×™×›×¨×•×Ÿ ×‘×¢×ª ×˜×¢×™× ×ª ×§×‘×¦×™× ×’×“×•×œ×™×
- **×ª××™×›×” ×‘×›×œ×™× ××ª×§×“××™×** â€“ ××ª××™× ×œÖ¾Big Data, Spark, AWS Athena ×•×¢×•×“

â— ×—×¡×¨×•×Ÿ:
- ×œ× × ×™×ª×Ÿ ×œ×¦×¤×™×™×” ×™×©×™×¨×” ×›××• Excel â€“ ×“×•×¨×© ×˜×¢×™× ×” ×‘×¢×–×¨×ª ×§×•×“ ××• ×›×œ×™× ×ª×•××›×™×

3. ×¡×™×›×•×:
----------
×”×§×•×“ ×¢×•×“×›×Ÿ ×›×š ×©×”×•× ×ª×•××š ×‘×©× ×™ ×”×¤×•×¨××˜×™× ×‘×¦×•×¨×” ×—×œ×§×”, ×ª×•×š ×©××™×¨×” ×¢×œ ×’××™×©×•×ª, ×§×¨×™××•×ª ×•× ×™×§×™×•×Ÿ ×§×•×“.
 ×”××©×ª××©×ª ×œ× ×¦×¨×™×›×” ×œ×“×¢×ª ××¨××© ××ª ××‘× ×” ×”×§×•×‘×¥ â€“ ×”×›×œ ××˜×•×¤×œ ××•×˜×•××˜×™×ª.

"""
